{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 5: Обучение и тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Libraries:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Простая Сверточная Нейронная Сеть (CNN)**\n",
    "\n",
    "Код определяет простую модель сверточной нейронной сети (CNN) с именем SimpleCNN, предназначенную для задач классификации изображений.  \n",
    " Эта архитектура состоит из двух сверточных слоев ( conv1и conv2), за каждым из которых следует активация выпрямленной линейной единицы (ReLU)   \n",
    " и уровни максимального пула. Полносвязный слой ( fc1) в конце дает окончательный результат для классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes: int = 2) -> None:\n",
    "        \"\"\"\n",
    "        Simple Convolutional Neural Network (CNN) model.\n",
    "\n",
    "        Parameters:\n",
    "        - num_classes: Number of classes for classification.\n",
    "        \"\"\"\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(32 * 32 * 32, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "\n",
    "        Parameters:\n",
    "        - x: Input tensor.\n",
    "\n",
    "        Returns:\n",
    "        - torch.Tensor: Output tensor.\n",
    "        \"\"\"\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Набор данных для классификации изображений**\n",
    "\n",
    "В данном коде определен класс пользовательского набора данных, CustomDataset, специально разработанный для задач классификации изображений.  \n",
    "Этот класс носит наследственный характер от класса Dataset библиотеки PyTorch, что обеспечивает удобное взаимодействие с загрузчиками данных.\n",
    "\n",
    "Структура Набора Данных:  \n",
    "- Каждое изображение загружается с использованием библиотеки PIL и преобразуется в формат RGB.  \n",
    "- Если указаны преобразования, они применяются к изображению.  \n",
    "- Метки получаются из предоставленного списка, и, если предоставлено отображение меток, строковые метки преобразуются в числовые индексы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_paths: list,\n",
    "        labels: list,\n",
    "        transform: transforms.Compose = None,\n",
    "        label_mapping: dict = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Custom dataset class for image classification.\n",
    "\n",
    "        Parameters:\n",
    "        - img_paths: List of image file paths.\n",
    "        - labels: List of corresponding labels.\n",
    "        - transform: Image transformations.\n",
    "        - label_mapping: Mapping of label strings to numerical indices.\n",
    "        \"\"\"\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Get the length of the dataset.\n",
    "\n",
    "        Returns:\n",
    "        - int: Length of the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple:\n",
    "        \"\"\"\n",
    "        Get item from the dataset.\n",
    "\n",
    "        Parameters:\n",
    "        - idx: Index of the item.\n",
    "\n",
    "        Returns:\n",
    "        - tuple: (image, label)\n",
    "        \"\"\"\n",
    "        img_path = self.img_paths[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label_str = self.labels[idx]\n",
    "        label = self.label_mapping[label_str] if self.label_mapping else int(\n",
    "            label_str)\n",
    "\n",
    "        return img, torch.tensor(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разделение Датасета**\n",
    "\n",
    "Данный код реализует функцию split_dataset, предназначенную для разделения датасета на обучающую, валидационную и тестовую выборки.\n",
    "\n",
    "Характеристики:  \n",
    "- Выводится информация о размерах общего датасета, а также размерах обучающей, валидационной и тестовой выборок.  \n",
    "- Данные случайным образом перемешиваются для обеспечения статистической независимости.  \n",
    "- Выбрасывается исключение, если недостаточно образцов для обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(\n",
    "    img_list: list,\n",
    "    labels: list,\n",
    "    train_size: float = 0.8,\n",
    "    val_size: float = 0.1,\n",
    "    test_size: float = 0.1,\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Split the dataset into training, validation, and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    - img_list: List of image file paths.\n",
    "    - labels: List of corresponding labels.\n",
    "    - train_size: Percentage of data for training.\n",
    "    - val_size: Percentage of data for validation.\n",
    "    - test_size: Percentage of data for testing.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: img_train, labels_train, img_val, labels_val, img_test, labels_test\n",
    "    \"\"\"\n",
    "    total_size = len(img_list)\n",
    "\n",
    "    print(f\"Total dataset size: {total_size}\")\n",
    "\n",
    "    train_size = int(total_size * train_size)\n",
    "    val_size = int(total_size * val_size)\n",
    "    test_size = int(total_size * test_size)\n",
    "\n",
    "    print(f\"Training dataset size: {train_size}\")\n",
    "    print(f\"Validation dataset size: {val_size}\")\n",
    "    print(f\"Test dataset size: {test_size}\")\n",
    "\n",
    "    if train_size <= 0:\n",
    "        raise ValueError(\"Not enough samples for training.\")\n",
    "\n",
    "    combined = list(zip(img_list, labels))\n",
    "    random.seed(42)\n",
    "    random.shuffle(combined)\n",
    "    img_list[:], labels[:] = zip(*combined)\n",
    "\n",
    "    img_val, labels_val = img_list[:val_size], labels[:val_size]\n",
    "    img_test, labels_test = img_list[val_size:val_size +\n",
    "                                     test_size], labels[val_size:val_size + test_size]\n",
    "    img_train, labels_train = img_list[val_size + test_size:val_size + test_size +\n",
    "                                       train_size], labels[val_size + test_size:val_size + test_size + train_size]\n",
    "\n",
    "    return img_train, labels_train, img_val, labels_val, img_test, labels_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Загрузка Датасета**\n",
    "\n",
    "Данный код реализует функцию load_dataset, предназначенную для загрузки датасета из CSV-файла и его последующего разделения на обучающую, валидационную и тестовую выборки.\n",
    "\n",
    "Особенности:  \n",
    "- Данные считываются из CSV-файла, представленного в виде датафрейма Pandas.  \n",
    "- Датасет случайным образом перемешивается для улучшения статистической независимости.  \n",
    "- Выводится информация о размерах оригинального датасета, а также размерах обучающей, валидационной и тестовой выборок.\n",
    "\n",
    "Обработка Исключений:  \n",
    "- Обработка исключений, таких как отсутствие файла, пустой файл, ошибки значения и неожиданная ошибка.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(\n",
    "    csv_path: str,\n",
    "    train_size: float = 0.8,\n",
    "    val_size: float = 0.1,\n",
    "    test_size: float = 0.1,\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Load dataset from a CSV file and split it into training, validation, and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    - csv_path: Path to the CSV file containing image annotations.\n",
    "    - train_size: Percentage of data for training.\n",
    "    - val_size: Percentage of data for validation.\n",
    "    - test_size: Percentage of data for testing.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: img_train, labels_train, img_val, labels_val, img_test, labels_test\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dframe = pd.read_csv(\n",
    "            csv_path, delimiter=\",\", names=[\"Absolute path\", \"Relative path\", \"Class\"]\n",
    "        )\n",
    "        img_list = dframe[\"Absolute path\"].tolist()\n",
    "        labels = dframe[\"Class\"].tolist()\n",
    "\n",
    "        if not img_list or not labels:\n",
    "            raise ValueError(\"Empty dataset: No images or labels found.\")\n",
    "\n",
    "        img_list, labels = list(img_list), list(labels)\n",
    "\n",
    "        combined = list(zip(img_list, labels))\n",
    "        random.seed(42)\n",
    "        random.shuffle(combined)\n",
    "        img_list[:], labels[:] = zip(*combined)\n",
    "\n",
    "        img_train, labels_train, img_val, labels_val, img_test, labels_test = split_dataset(\n",
    "            img_list, labels, train_size=train_size, val_size=val_size, test_size=test_size\n",
    "        )\n",
    "\n",
    "        return img_train, labels_train, img_val, labels_val, img_test, labels_test\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at path '{csv_path}'\")\n",
    "        return [], [], [], [], [], []\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Error: Empty file at path '{csv_path}'\")\n",
    "        return [], [], [], [], [], []\n",
    "    except ValueError as ve:\n",
    "        print(f\"ValueError: {ve}\")\n",
    "        return [], [], [], [], [], []\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return [], [], [], [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Расчет Точности (Accuracy)**\n",
    "\n",
    "Данный код содержит функцию calculate_accuracy, которая предназначена для вычисления точности (accuracy) модели на основе предсказанных и истинных меток.\n",
    "\n",
    "Описание:  \n",
    "- Код использует генератор списка для проверки, сколько из предсказанных меток совпадают с истинными.  \n",
    "- Расчет производится путем деления числа правильных предсказаний на общее количество предсказаний.\n",
    "\n",
    "Возвращаемое Значение:  \n",
    "- Вещественное число, представляющее процент точности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(predictions: list, true_labels: list) -> float:\n",
    "    \"\"\"\n",
    "    Calculate accuracy given predicted and true labels.\n",
    "\n",
    "    Parameters:\n",
    "    - predictions: Predicted labels.\n",
    "    - true_labels: True labels.\n",
    "\n",
    "    Returns:\n",
    "    - float: Accuracy.\n",
    "    \"\"\"\n",
    "    correct = sum(p == t for p, t in zip(predictions, true_labels))\n",
    "    total = len(predictions)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**Визуализация Результатов Обучения**\n",
    "\n",
    "Данный код определяет функцию plot_training_results, которая предназначена для построения графиков результатов обучения и валидации.\n",
    "\n",
    "Параметры:  \n",
    "- train_losses: Список значений функции потерь на обучающей выборке.  \n",
    "- val_losses: Список значений функции потерь на валидационной выборке.  \n",
    "- val_accuracies: Список значений точности на валидационной выборке.  \n",
    "- learning_rate: Скорость обучения (learning rate).  \n",
    "- batch_size: Размер пакета (batch size).\n",
    "\n",
    "Детали Графика:\n",
    "\n",
    "Левый График (subplot 1, 2, 1):  \n",
    "- Линии для функции потерь на обучающей (Training Loss) и валидационной (Validation Loss) выборках.  \n",
    "- Точки (marker='o') обозначают значения на каждой эпохе.  \n",
    "- Заголовок графика: \"Training and Validation Loss\".  \n",
    "- Ось X: Эпохи.  \n",
    "- Ось Y: Значения функции потерь.  \n",
    "- Легенда для обозначения линий.\n",
    "\n",
    "Правый График (subplot 1, 2, 2):  \n",
    "- Линия для точности на валидационной выборке (Validation Accuracy).  \n",
    "- Точки (marker='o') обозначают значения на каждой эпохе.  \n",
    "- Заголовок графика: \"Validation Accuracy\".  \n",
    "- Ось X: Эпохи.  \n",
    "- Ось Y: Значения точности.  \n",
    "\n",
    "- Сверху: Общий заголовок, включающий значения скорости обучения и размера пакета.\n",
    "Легенда для обозначения линии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_results(\n",
    "    train_losses: list,\n",
    "    val_losses: list,\n",
    "    val_accuracies: list,\n",
    "    learning_rate: float,\n",
    "    batch_size: int,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot training and validation results.\n",
    "\n",
    "    Parameters:\n",
    "    - train_losses: Training losses.\n",
    "    - val_losses: Validation losses.\n",
    "    - val_accuracies: Validation accuracies.\n",
    "    - learning_rate: Learning rate.\n",
    "    - batch_size: Batch size.\n",
    "    \"\"\"\n",
    "    epochs = list(range(1, len(train_losses) + 1))\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label='Training Loss', marker='o')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss', marker='o')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, val_accuracies, label='Validation Accuracy',\n",
    "             marker='o', color='green')\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.suptitle(f'Learning Rate: {learning_rate}, Batch Size: {batch_size}')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функция Обучения Модели**\n",
    "\n",
    "Эта функция (train_model) выполняет обучение нейронной сети на заданных наборах данных и выводит информацию о процессе обучения, включая потери на обучающем и валидационном наборах, а также точность на валидационном наборе.\n",
    "\n",
    "Параметры:\n",
    "- model: Нейронная сеть для обучения.\n",
    "- train_loader: Загрузчик данных для обучающего набора.\n",
    "- val_loader: Загрузчик данных для валидационного набора.\n",
    "- device: Устройство для обучения (например, \"cuda\" или \"cpu\").\n",
    "- num_epochs: Количество эпох обучения.\n",
    "- learning_rate: Темп обучения.\n",
    "\n",
    "Детали:\n",
    "- Модель и данные перемещаются на указанное устройство.\n",
    "- Используется кросс-энтропийная функция потерь и оптимизатор Adam.\n",
    "- В каждой эпохе:\n",
    "    - Модель переводится в режим обучения (model.train()).\n",
    "    - Обучающий набор прогоняется через модель, потери вычисляются и обновляются веса.\n",
    "    - Записываются потери на обучающем наборе.\n",
    "    - Модель переводится в режим оценки (model.eval()).\n",
    "    - Валидационный набор используется для оценки модели, вычисляются потери и точность.\n",
    "    - Записываются потери и точность на валидационном наборе.\n",
    "\n",
    "Вывод:\n",
    "- В каждой эпохе выводится информация о потерях и точности на валидационном наборе.\n",
    "\n",
    "Возвращаемое значение:\n",
    "- Возвращается кортеж, содержащий списки обучающих потерь, валидационных потерь и валидационных точностей.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    device: torch.device,\n",
    "    num_epochs: int = 10,\n",
    "    learning_rate: float = 0.001,\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Train the given model using the specified data loaders.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Neural network model.\n",
    "    - train_loader: Training data loader.\n",
    "    - val_loader: Validation data loader.\n",
    "    - device: Device for training (e.g., \"cuda\" or \"cpu\").\n",
    "    - num_epochs: Number of training epochs.\n",
    "    - learning_rate: Learning rate.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: train_losses, val_losses, val_accuracies\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_train_losses = []\n",
    "        for images, labels in train_loader:\n",
    "            images = torch.stack([img.to(device) for img in images])\n",
    "            labels = torch.as_tensor(\n",
    "                labels, dtype=torch.long).clone().detach().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_train_losses.append(loss.item())\n",
    "\n",
    "        avg_train_loss = sum(epoch_train_losses) / len(epoch_train_losses)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            predictions = []\n",
    "            true_labels = []\n",
    "            for images, labels in val_loader:\n",
    "                images = torch.stack([img.to(device) for img in images])\n",
    "                labels = torch.as_tensor(\n",
    "                    labels, dtype=torch.long).clone().detach().to(device)\n",
    "                outputs = model(images)\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                predictions.extend(predicted.cpu().numpy())\n",
    "                true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "            accuracy = calculate_accuracy(predictions, true_labels)\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "            val_losses.append(val_loss)\n",
    "            val_accuracies.append(accuracy)\n",
    "\n",
    "    return train_losses, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оценка Модели на Тестовом Наборе**\n",
    "\n",
    "Этот код определяет функцию evaluate_model, которая оценивает производительность модели на тестовом наборе данных и выводит точность.\n",
    "\n",
    "Параметры:\n",
    "- model: Нейронная сеть для оценки.\n",
    "- test_loader: Загрузчик данных для тестового набора.\n",
    "- device: Устройство для оценки (например, \"cuda\" или \"cpu\").\n",
    "\n",
    "Детали:\n",
    "- Модель отправляется на указанное устройство (model.to(device)).\n",
    "- Модель переводится в режим оценки (model.eval()).\n",
    "- Без вычисления градиентов с использованием torch.no_grad(), модель оценивает тестовый набор данных.\n",
    "- Предсказания и истинные метки собираются в списки для последующего вычисления точности с использованием функции calculate_accuracy.\n",
    "\n",
    "Вывод:\n",
    "- Выводится точность модели на тестовом наборе данных.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model: nn.Module, test_loader: DataLoader, device: torch.device) -> None:\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test set and print the accuracy.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Neural network model.\n",
    "    - test_loader: Test data loader.\n",
    "    - device: Device for evaluation (e.g., \"cuda\" or \"cpu\").\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_predictions = []\n",
    "        test_true_labels = []\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_predictions.extend(predicted.cpu().numpy())\n",
    "            test_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    test_accuracy = calculate_accuracy(test_predictions, test_true_labels)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Основная Функция: Обучение и Оценка Модели**\n",
    "\n",
    "Эта основная функция (main) выполняет обучение и оценку модели для различных комбинаций темпа обучения и размера пакета.\n",
    "\n",
    "Параметры:  \n",
    "- csv_path: Путь к файлу CSV с аннотациями изображений.  \n",
    "- num_epochs: Количество эпох обучения.\n",
    "\n",
    "Детали:  \n",
    "- Определяется устройство для обучения (cuda если доступно, иначе cpu).  \n",
    "- Загружаются данные и разделяются на обучающий, валидационный и тестовый наборы.  \n",
    "- Создается отображение меток для преобразования строковых меток в числовые индексы.  \n",
    "- Определяются темпы обучения и размеры пакетов для экспериментов.  \n",
    "- Для каждой комбинации темпа обучения и размера пакета:  \n",
    "    - Создается набор данных и загрузчики данных для обучения, валидации и тестирования.  \n",
    "    - Инициализируется модель CNN (SimpleCNN) с количеством классов, соответствующим количеству уникальных меток.  \n",
    "    - Модель обучается с использованием функции train_model.  \n",
    "    - Результаты обучения визуализируются с использованием функции plot_training_results.  \n",
    "    - Модель оценивается на тестовом наборе данных с использованием функции evaluate_model.\n",
    "\n",
    "Вывод:  \n",
    "- Для каждой комбинации темпа обучения и размера пакета выводится информация о ходе обучения и результаты оценки на тестовом наборе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(csv_path: str, num_epochs: int = 10) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Main function for training and evaluating the model.\n",
    "\n",
    "    Parameters:\n",
    "    - csv_path: Path to the CSV file containing image annotations.\n",
    "    - num_epochs: Number of training epochs.\n",
    "\n",
    "    Returns:\n",
    "    - nn.Module: Trained neural network model.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    img_train, labels_train, img_val, labels_val, img_test, labels_test = load_dataset(\n",
    "        csv_path)\n",
    "\n",
    "    unique_labels = set(labels_train + labels_val + labels_test)\n",
    "    label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "    learning_rates = [0.001, 0.01, 0.1]\n",
    "    batch_sizes = [16, 32, 64]\n",
    "\n",
    "    for learning_rate in learning_rates:\n",
    "        for batch_size in batch_sizes:\n",
    "            print(\n",
    "                f\"\\nExperiment: Learning Rate = {learning_rate}, Batch Size = {batch_size}\")\n",
    "\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize((128, 128)),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "\n",
    "            train_dataset = CustomDataset(\n",
    "                img_train, labels_train, transform, label_mapping)\n",
    "            val_dataset = CustomDataset(\n",
    "                img_val, labels_val, transform, label_mapping)\n",
    "            test_dataset = CustomDataset(\n",
    "                img_test, labels_test, transform, label_mapping)\n",
    "\n",
    "            train_loader = DataLoader(\n",
    "                train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "            val_loader = DataLoader(\n",
    "                val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "            test_loader = DataLoader(\n",
    "                test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "            model = SimpleCNN(num_classes=len(unique_labels)).to(device)\n",
    "\n",
    "            train_losses, val_losses, val_accuracies = train_model(model, train_loader, val_loader, device,\n",
    "                                                                   num_epochs=num_epochs, learning_rate=learning_rate)\n",
    "\n",
    "            plot_training_results(train_losses, val_losses,\n",
    "                                  val_accuracies, learning_rate, batch_size)\n",
    "\n",
    "            evaluate_model(model, test_loader, device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Основной блок выполнения: Обучение и Оценка Модели**\n",
    "\n",
    "В этом блоке кода осуществляется обучение нейронной сети и оценка ее производительности.\n",
    "\n",
    "Шаги:\n",
    "1. Определение устройства для обучения (GPU или CPU).\n",
    "2. Загрузка и подготовка наборов данных для обучения, валидации и тестирования.\n",
    "3. Создание уникального отображения меток классов.\n",
    "4. Обучение модели с использованием функции main, устанавливая количество эпох в 10.\n",
    "5. Сохранение обученной модели в файл simple_cnn_model.pth.\n",
    "6. Загрузка сохраненной модели для дальнейшей оценки.\n",
    "7. Подготовка и отправка изображения для предсказания класса с использованием новой модели.\n",
    "8. Вывод предсказанного индекса класса для примера изображения.\n",
    "9. Отображение примера изображения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    img_train, labels_train, img_val, labels_val, img_test, labels_test = load_dataset(\n",
    "        \"annotation.csv\")\n",
    "\n",
    "    unique_labels = list(set(labels_train + labels_val +\n",
    "                         labels_test)) \n",
    "    label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "    trained_model = main(\"annotation.csv\", num_epochs=10)\n",
    "\n",
    "    model_save_path = \"simple_cnn_model.pth\"\n",
    "    torch.save(trained_model.state_dict(), model_save_path)\n",
    "    print(f\"Trained model saved at: {model_save_path}\")\n",
    "\n",
    "    new_model = SimpleCNN(num_classes=len(unique_labels)).to(device)\n",
    "    new_model.load_state_dict(torch.load(model_save_path))\n",
    "    new_model.eval()\n",
    "\n",
    "    img_paths = [\n",
    "        \"dataset/leopard/0012.jpg\",\n",
    "        \"dataset/tiger/0004.jpg\",\n",
    "    ]\n",
    "\n",
    "    for img_path in img_paths:\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        sample_image = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = new_model(sample_image)\n",
    "            _, predicted_class = torch.max(output, 1)\n",
    "\n",
    "        print(\n",
    "            f\"Predicted class index for image {img_path}: {predicted_class.item()}\")\n",
    "\n",
    "        img_array = transforms.ToPILImage()(sample_image.squeeze(0).cpu())\n",
    "        plt.imshow(img_array)\n",
    "        plt.title(f\"Predicted class: {predicted_class.item()}\")\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
