{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 5: Обучение и тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала выполним импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List, Tuple, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Читаем пути из аннотаций формата csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dframe = pd.read_csv(cat_csv_path, delimiter=\",\", names=[\"Absolute path\", \"Relative path\", \"Class\"])\n",
    "    dog_dframe = pd.read_csv(dog_csv_path, delimiter=\",\", names=[\"Absolute path\", \"Relative path\", \"Class\"])\n",
    "\n",
    "    cat_images = cat_dframe[\"Absolute path\"].tolist()\n",
    "    dog_images = dog_dframe[\"Absolute path\"].tolist()\n",
    "\n",
    "    return cat_images, dog_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "img in index 0: The absolute path\n",
    "\n",
    "img in index 1: C:/Users/User/Desktop/testing/dataset\\cat\\cat.4001.jpg\n",
    "\n",
    "img in index 2: C:/Users/User/Desktop/testing/dataset\\cat\\cat.4002.jpg\n",
    "\n",
    "img in index 0: The absolute path\n",
    "\n",
    "img in index 1: C:/Users/User/Desktop/testing/dataset\\dog\\dog.4001.jpg\n",
    "\n",
    "img in index 2: C:/Users/User/Desktop/testing/dataset\\dog\\dog.4002.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделение данных на тренировочные, тестовые и валидационные в пропорциях: 80 на 10 на 10, соответственно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train_data, cat_test_val_data = train_test_split(cat_images, test_size=(test_size + val_size), random_state=42)\n",
    "    cat_test_data, cat_valid_data = train_test_split(cat_test_val_data, test_size=(val_size / (test_size + val_size)), random_state=42)\n",
    "\n",
    "    dog_train_data, dog_test_val_data = train_test_split(dog_images, test_size=(test_size + val_size), random_state=42)\n",
    "    dog_test_data, dog_valid_data = train_test_split(dog_test_val_data, test_size=(val_size / (test_size + val_size)), random_state=42)\n",
    "\n",
    "    train_data = cat_train_data + dog_train_data\n",
    "    test_data = cat_test_data + dog_test_data\n",
    "    valid_data = cat_valid_data + dog_valid_data\n",
    "\n",
    "    return train_data, test_data, valid_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1619\n",
    "202\n",
    "204"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = np.random.randint(1,len(img_list),size=10)\n",
    "\n",
    "fig = plt.figure()\n",
    "i=1\n",
    "for idx in random_idx:\n",
    "    ax = fig.add_subplot(2,5,i)\n",
    "    img = Image.open(img_list[idx])\n",
    "    plt.imshow(img)\n",
    "    i+=1\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](fig1.png)\n",
    "![Alt text](fig2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс для хранения датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data : List[str], labels : List[int], transform : Any = None):\n",
    "        \"\"\"\n",
    "        create custom dataset\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : List[str]\n",
    "        labels : List[int]\n",
    "        transform : Any, optional\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        get the length of dataset\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index : int) -> Tuple[torch.Tensor, int]:\n",
    "        \"\"\"\n",
    "        method for get img and him label\n",
    "        Parameters\n",
    "        ----------\n",
    "        index : int\n",
    "        \"\"\"\n",
    "        img_path = self.data[index]\n",
    "        img = Image.open(img_path)\n",
    "        img = self.transform(img) if self.transform else transforms.ToTensor()(img)\n",
    "        label = self.labels[index]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь мы подготавливаем размеры картинок для дальнейшего обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка размера картинок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img, sample_label = trenkaset[0]\n",
    "    print(f\"Shape of an image: {sample_img.shape}, Label: {sample_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of an image: torch.Size([3, 224, 224]), Label: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь создаем класс сверточной модели нейронной сети:\n",
    "1. 3-и слоя свертки и 2-а полностью связанных слоя;\n",
    "2. пакетная нормализация для ограничения обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cnn(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional neural network model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super(Cnn, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size = 3, padding = 0, stride = 2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size = 3, padding = 0, stride = 2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size = 3, padding = 0, stride = 2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(3*3*64,10)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(10, 2)\n",
    "        self.relu = nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "if device =='cuda':\n",
    "    torch.cuda.manual_seed_all(1234)\n",
    "    \n",
    "model = Cnn()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cnn(\n",
    "  (layer1): Sequential(\n",
    "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
    "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (2): ReLU()\n",
    "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  )\n",
    "  (layer2): Sequential(\n",
    "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
    "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (2): ReLU()\n",
    "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  )\n",
    "  (layer3): Sequential(\n",
    "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
    "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (2): ReLU()\n",
    "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  )\n",
    "  (fc1): Linear(in_features=576, out_features=10, bias=True)\n",
    "  (dropout): Dropout(p=0.5, inplace=False)\n",
    "  (fc2): Linear(in_features=10, out_features=2, bias=True)\n",
    "  (relu): ReLU()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, отрисовывающая графики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(epochs : int, acc : List[float], loss : List[float], v_acc : List[float], v_loss : List[float]) -> None:\n",
    "    \"\"\"\n",
    "    creates graphs based on the learning results for train and validation sets.\n",
    "    Parameters\n",
    "    ----------\n",
    "    epochs : int\n",
    "    acc : List[float]\n",
    "    loss : List[float]\n",
    "    v_acc : List[float]\n",
    "    v_loss : List[float]\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    ax1.plot(range(epochs), acc, color=\"orange\", label=\"Train accuracy\")\n",
    "    ax2.plot(range(epochs), loss, color=\"orange\", label=\"Train loss\")\n",
    "    \n",
    "    ax1.plot(range(epochs), v_acc, color=\"steelblue\", label=\"Validation accuracy\")\n",
    "    ax2.plot(range(epochs), v_loss, color=\"steelblue\", label=\"Validation loss\")\n",
    "    \n",
    "    ax1.legend()\n",
    "    ax2.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цикл обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(epochs: int, batch_size: int, lear: float, train_data: CustomDataset, test_data: CustomDataset, valid_data: CustomDataset) -> Tuple[list, Cnn]:\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=lear)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    accuracy_values = []\n",
    "    loss_values = []\n",
    "    valid_accuracy_values = []\n",
    "    valid_loss_values = []\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        dataset=valid_data, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_data, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "\n",
    "        for data, label in train_loader:\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc = (output.argmax(dim=1) == label).float().mean()\n",
    "            epoch_accuracy += acc / len(train_loader)\n",
    "            epoch_loss += loss / len(train_loader)\n",
    "\n",
    "        print(f\"Epoch : {epoch + 1}, train accuracy : {epoch_accuracy}, train loss : {epoch_loss}\")\n",
    "        accuracy_values.append(epoch_accuracy.item())\n",
    "        loss_values.append(epoch_loss.item())\n",
    "    with torch.no_grad():\n",
    "            model.eval()\n",
    "            epoch_val_accuracy = 0\n",
    "            epoch_val_loss = 0\n",
    "\n",
    "            for data, label in valid_loader:\n",
    "                data = data.to(device)\n",
    "                label = label.to(device)\n",
    "\n",
    "                val_output = model(data)\n",
    "                val_loss = criterion(val_output, label)\n",
    "\n",
    "                acc = (val_output.argmax(dim=1) == label).float().mean()\n",
    "                epoch_val_accuracy += acc / len(valid_loader)\n",
    "                epoch_val_loss += val_loss / len(valid_loader)\n",
    "\n",
    "            print(f\"Epoch : {epoch + 1}, val_accuracy : {epoch_val_accuracy}, val_loss : {epoch_val_loss}\")\n",
    "            valid_accuracy_values.append(epoch_val_accuracy.item())\n",
    "            valid_loss_values.append(epoch_val_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем 9 запусков с разными параметрами(эпохи, батчи, и скорость обучения)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with epochs=5, batch_size=32, learning_rate=0.001\n",
    "![Alt text](1launch.png)\n",
    "Training with epochs=10, batch_size=64, learning_rate=0.001\n",
    "![Alt text](2launch.png)\n",
    "Training with epochs=20, batch_size=256, learning_rate=0.001\n",
    "![Alt text](3launch.png)\n",
    "Training with epochs=25, batch_size=256, learning_rate=0.005\n",
    "![Alt text](4launch.png)\n",
    "Training with epochs=25, batch_size=512, learning_rate=0.005\n",
    "![Alt text](5launch.png)\n",
    "Training with epochs=30, batch_size=512, learning_rate=0.015\n",
    "![Alt text](6launch.png)\n",
    "Training with epochs=40, batch_size=512, learning_rate=0.015\n",
    "![Alt text](7launch.png)\n",
    "Training with epochs=50, batch_size=1024, learning_rate=0.015\n",
    "![Alt text](8launch.png)\n",
    "Training with epochs=15, batch_size=128, learning_rate=0.1\n",
    "![Alt text](9launch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На мой взгляд, для сохранения лучше использовать 4 модель, потому что у неё более менее стабильные маленькие потери."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь заново запускаем и сохраняем csv файл и модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(rose_probs : List[Tuple[int, float]], csv_path : str, model : nn.Module, model_path : str) -> None:\n",
    "    \"\"\"\n",
    "    func for saving the result in csv and the model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rose_probs : List[Tuple[int, float]]\n",
    "    csv_path : str\n",
    "    model : nn.Module\n",
    "    model_path : str\n",
    "    \"\"\"\n",
    "    idx = list(i for i in range(len(rose_probs)))\n",
    "    prob = list(map(lambda x: x[1], rose_probs))\n",
    "    submission = pd.DataFrame({\"id\": idx, \"label\": prob})\n",
    "    submission.to_csv(csv_path, index=False)\n",
    "\n",
    "    torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь повторно инициализируем модель и тестируем ее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Cnn().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {0: \"cat\", 1: \"dog\"}\n",
    "\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20, 12), facecolor=\"w\")\n",
    "    submission = pd.read_csv('E:\\\\education\\\\pythonLab\\\\pythonLabs\\\\Lab5\\\\result.csv')\n",
    "\n",
    "    for ax in axes.ravel():\n",
    "        i = random.choice(submission[\"id\"].values)\n",
    "        label = submission.loc[submission[\"id\"] == i, \"label\"].values[0]\n",
    "        if label > 0.5:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "\n",
    "        img_path = testikset.data[i]\n",
    "        img = Image.open(img_path)\n",
    "        img_tensor = testikset.transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = loaded_model(img_tensor)\n",
    "\n",
    "        predicted_label = torch.argmax(output).item()\n",
    "\n",
    "        ax.set_title(f\"True: {class_mapping[label]}, Predicted: {class_mapping[predicted_label]}\")\n",
    "        ax.imshow(img)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](result.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
